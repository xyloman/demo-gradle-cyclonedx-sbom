# Getting Started

### Reference Documentation
For further reference, please consider the following sections:

* [Official Gradle documentation](https://docs.gradle.org)
* [Spring Boot Gradle Plugin Reference Guide](https://docs.spring.io/spring-boot/3.3.3/gradle-plugin)
* [Create an OCI image](https://docs.spring.io/spring-boot/3.3.3/gradle-plugin/packaging-oci-image.html)
* [CycloneDX SBOM support](https://docs.spring.io/spring-boot/reference/actuator/endpoints.html#actuator.endpoints.sbom)
* [Spring Web](https://docs.spring.io/spring-boot/docs/3.3.3/reference/htmlsingle/index.html#web)

### Guides
The following guides illustrate how to use some features concretely:

* [Building a RESTful Web Service](https://spring.io/guides/gs/rest-service/)
* [Serving Web Content with Spring MVC](https://spring.io/guides/gs/serving-web-content/)
* [Building REST services with Spring](https://spring.io/guides/tutorials/rest/)

### Additional Links
These additional references should also help you:

* [Gradle Build Scans – insights for your project's build](https://scans.gradle.com#gradle)

### Scan Software Bill of Materials for Vulnerabilities with osv-scanner

First install the osv-scanner using brew.

```bash
brew install osv-scanner
```

Then perform a gradle build of the project. Ensure to clean if any dependencies change on the project. The cyclonedx 
plugin does not trigger rerunning with the dependencies of the project change. More investigation needed. 

```bash
./gradlew clean build
```

A new report should be included in the build directory containing the cyclonedx SBOM.

```bash
cat build/reports/application.cdx.json
```

To scan the `application.cdx.json` for vulnerabilities execute.

```bash
osv-scanner scan --sbom build/reports/application.cdx.json
```

The `osv-scanner` will produce output similar to the following:

```text
╭─────────────────────────────────────┬──────┬───────────┬───────────────────────────────────────────┬──────────┬────────────────────────────────────╮
│ OSV URL                             │ CVSS │ ECOSYSTEM │ PACKAGE                                   │ VERSION  │ SOURCE                             │
├─────────────────────────────────────┼──────┼───────────┼───────────────────────────────────────────┼──────────┼────────────────────────────────────┤
│ https://osv.dev/GHSA-5mg8-w23w-74h3 │ 3.3  │ Maven     │ com.google.guava:guava                    │ 30.1-jre │ build/reports/application.cdx.json │
│ https://osv.dev/GHSA-7g45-4rm6-3mm3 │ 5.5  │ Maven     │ com.google.guava:guava                    │ 30.1-jre │ build/reports/application.cdx.json │
│ https://osv.dev/GHSA-wm9w-rjj3-j356 │ 8.7  │ Maven     │ org.apache.tomcat.embed:tomcat-embed-core │ 10.1.24  │ build/reports/application.cdx.json │
│ https://osv.dev/GHSA-chfm-68vv-pvw5 │      │ Maven     │ org.xmlunit:xmlunit-core                  │ 2.9.1    │ build/reports/application.cdx.json │
│ https://osv.dev/GHSA-2cww-fgmg-4jqc │ 8.1  │ Maven     │ org.keycloak:keycloak-services            │ 24.0.4   │ build/reports/application.cdx.json │
│ https://osv.dev/GHSA-69fp-7c8p-crjr │ 7.5  │ Maven     │ org.keycloak:keycloak-services            │ 24.0.4   │ build/reports/application.cdx.json │
╰─────────────────────────────────────┴──────┴───────────┴───────────────────────────────────────────┴──────────┴────────────────────────────────────╯
```

This is an example of a project that has dependencies declared that have vulnerabilities. The developer has the ability
to discover these vulnerabilities by scanning the [application.cdx.json](build/reports/application.cdx.json) report 
generated by the gradle build.

### Constructing an Image

The [Dockerfile](./Dockerfile) contained in this repository follows the best practices for Spring Boot 3.3.x to make use of 
the layer features and the CDS support. More details can be found in the [Spring Boot Reference on Dockerfiles](https://docs.spring.io/spring-boot/reference/packaging/container-images/dockerfiles.html#packaging.container-images.dockerfiles.cds).

```bash
docker buildx build --load -t xyloman/demo-gradle-cyclonedx-sbom .
```

One addition that is made to the Dockerfile is to copy the `application.cdx.json` from the `./build/reports` folder into 
the root of the image. We can configure syft to incorporate the SBOM generated at build time instead of relying on syft to
identify the Java dependencies. Using the flag `select-catalogers` when executing the syft CLI can help adjust what syft 
should be looking for in the image. In our case, we are going to disable the java cataloger because the results already exist in the 
`application.cdx.json` file.  We also need to enable the `sbom-cataloger` which will ensure that any SBOM that is found 
in the image file system will be included in the resulting SBOM produced by syft. All together the command would look like the following:

```bash
SYFT_FORMAT_PRETTY=true syft xyloman/demo-gradle-cyclonedx-sbom
```

Notice no flags are included on the CLI command. We have gone ahead and captured all of the flags in the [config.yaml](.syft/config.yaml) 
file. This location will also be used by the `anchore/sbom-action` when building during CI. Ensuring that the flags set 
when running locally are the same as running during CI. Later on we will generate an attestation of the SBOM associated with the image, 
we will want that content as compact as possible so we will set the `SYFT_FORMAT_PRETTY` env var when running locally to 
make the consumption of the content easier for humans.

### GitHub Action Workflow for producing SLSA attested signed executable JAR and Image

Full workflow can be found [here](.github/workflows/gradle.yml)

General highlights:
- Use Gradle to build and publish the executable Jar to [GitHub Maven Repository](https://github.com/xyloman/demo-gradle-cyclonedx-sbom/packages/2294478)
- Use the GitHub [attest](https://github.com/actions/attest) action to generate signed attestations.
  - Attestations generated for an executable jar and generated SBOM.
  - Attestations generated for container image containing executable jar and generated SBOM.
  - Attestations are published on the [attestation](https://github.com/xyloman/demo-gradle-cyclonedx-sbom/attestations) tab for the project.
- Use Docker [build-push](https://github.com/docker/build-push-action) action to publish built container to [GitHub Container Registry](https://github.com/xyloman/demo-gradle-cyclonedx-sbom/pkgs/container/demo-gradle-cyclonedx-sbom).
- Use `gh attestation verify` command to verify jar attestations before placing into container image. Boundary could be created here where one repository builds the executable jar and another repository would be responsible for container image building. See note below, enforcement of the provenance of the container can be done by verifying the workflow used to produced the artifact. Rejecting images that have not used the workflow. 
- Use the Anchor [sbom-action](https://github.com/anchore/sbom-action) and the [config.yaml](.syft/config.yaml) to control generation of SBOM containing both accurate Java dependencies and Container Image Dependencies.

### Enforce artifact attestations on Kubernetes cluster with Sigstore Policy Controller

Reference: [GitHub - Enforcing artifact attestations with a Kubernetes admission controller](https://docs.github.com/en/actions/security-for-github-actions/using-artifact-attestations/enforcing-artifact-attestations-with-a-kubernetes-admission-controller)

Create a k3d cluster for testing the setup
```bash
k3d cluster create attestations -p "8880:80@loadbalancer"
```

Ensure we are targeting the attestation k3d instance
```bash
kubectl config use-context k3d-attestations
```

Install the policy controller on the k3d cluster reference [GitHub Artifact Attestations Helm Charts](https://github.com/github/artifact-attestations-helm-charts)
```bash
helm upgrade policy-controller --install --atomic \
  --create-namespace --namespace artifact-attestations \
  oci://ghcr.io/github/artifact-attestations-helm-charts/policy-controller \
  --version v0.10.0-github8
```

Create namespace and label namespace that attestation policy will be enforced
```bash
kubectl create namespace dev
kubectl label namespace dev policy.sigstore.dev/include=true
```

Apply the demo workload to the cluster
```bash
kubectl apply  -n dev -f src/main/kubernetes/deployment.yaml
```

The apply should fail with the following exception
```bash
Error from server (BadRequest): error when creating "src/main/kubernetes/deployment.yaml": admission webhook "policy.sigstore.dev" denied the request: validation failed: no matching policies: spec.template.spec.containers[0].image
ghcr.io/xyloman/demo-gradle-cyclonedx-sbom@sha256:de29abdaa10b3d76dd3d30c49cc2d205ef47055ddef880f18cf31546a91a2e72
```

The failure above was due to no `ClusterImagePolicy` exists but the namespace is configured to enforce any policies defined. With the absence of the `ClusterImagePolicy` the namespace will deny all admissions.

Create trust policies that will only trust images from my GitHub organization. In this example the organization would be `xyloman`.
```bash
helm upgrade trust-policies --install --atomic \
 --namespace artifact-attestations \
 oci://ghcr.io/github/artifact-attestations-helm-charts/trust-policies \
 --version v0.6.1 \
 --set policy.enabled=true \
 --set policy.organization=xyloman
```

The `ClusterImagePolicy` created by the above helm chart upgrade is similar to the following. When the chart is configured with 
`policy.organization=xyloman` this mutates the `subjectRegExp` configured for the `spec.authorities.keyless.identities.subjectRegEx` to 
include the org that owned the workflow that performed the signing. If a shared workflow was reused that existed in a different
organization on GitHub that would have to be accounted for in the regex for the subject for instance `https://github.com/org-that-owns-shared-workflow/.*/\.github/workflows/.*`.
The fork of the Policy Controller was made by GitHub to support `signatureFormat` equal to `bundle`. The provenance in-toto
attestation will be wrapped in a [SigStore Bundle](https://github.com/sigstore/cosign/blob/main/specs/BUNDLE_SPEC.md) and pushed
to the registry along side the image. When validation is performed the Policy controller will pull the bundle and verify 
the contents satisfy the authority details in the `ClusterImagePolicy`. The signature key must match a certificate authority
in the `TrustRoot` resource created by the `artifact-attestations-helm-charts`. In the case of this repository, the public good
SigStore instance was used which means the trust material from SigStore will be used to validate the signature on the image.

NOTE: For hardening the supply chain and to avoid needing to build all of the container images using a shared repository, operations could
democratize the container image building to a shared workflow/action that has the enterprises best practices encapsulated. The `ClusterImagePolicy`
below could be used to verify the `subjectRegEx` matches the shared workflow action. GitHub will ensure through the use of [OIDC claims](https://docs.github.com/en/actions/security-for-github-actions/security-hardening-your-deployments/about-security-hardening-with-openid-connect#understanding-the-oidc-token)
that the `job_workflow_ref` claim matches the workflow of the shared action. The policy controller will have access to this information
through the build provenance information in the SLSA attestation via the `subjectAlternativeName` field.
```yaml
apiVersion: policy.sigstore.dev/v1beta1
kind: ClusterImagePolicy
metadata:
  name: github-policy
spec:
  authorities:
    - attestations:
        - name: require-attestation
          predicateType: https://slsa.dev/provenance/v1
      ctlog:
        url: https://rekor.sigstore.dev
      keyless:
        identities:
          - issuer: https://token.actions.githubusercontent.com
            subjectRegExp: https://github.com/xyloman/.*/\.github/workflows/.*
        url: https://fulcio.sigstore.dev
      name: public-good
      signatureFormat: bundle
  images:
  - glob: '**'
  mode: enforce
```

Attempt to apply the demo workload to the cluster again
```bash
kubectl apply  -n dev -f src/main/kubernetes/deployment.yaml
```
                                         